# fufanrag RAGæ¡†æ¶æ¨¡å—åŒ–è®¾è®¡ä¸ç®¡é“æµç¨‹åˆ†æ

## 1. RAGæ¡†æ¶æ ¸å¿ƒæ¨¡å—æ¦‚è¿°

### 1.1 æ¨¡å—åŒ–è®¾è®¡ç†å¿µ

RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ¡†æ¶é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†å¤æ‚çš„é—®ç­”ç³»ç»Ÿæ‹†åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹çš„åŠŸèƒ½æ¨¡å—ã€‚æ¯ä¸ªæ¨¡å—è´Ÿè´£ç‰¹å®šçš„ä»»åŠ¡ï¼Œé€šè¿‡æ ‡å‡†åŒ–æ¥å£è¿›è¡Œæ•°æ®ä¼ é€’å’Œåä½œã€‚è¿™ç§è®¾è®¡æ¨¡å¼çš„ä¼˜åŠ¿åœ¨äºï¼š

- **èŒè´£åˆ†ç¦»**ï¼šæ¯ä¸ªæ¨¡å—ä¸“æ³¨äºå•ä¸€åŠŸèƒ½ï¼Œé™ä½ä»£ç å¤æ‚åº¦
- **çµæ´»ç»„åˆ**ï¼šå¯ä»¥æ ¹æ®éœ€æ±‚è‡ªç”±æ›¿æ¢å’Œç»„åˆä¸åŒæ¨¡å—
- **æ˜“äºæ‰©å±•**ï¼šæ–°å¢åŠŸèƒ½åªéœ€æ·»åŠ æ–°æ¨¡å—ï¼Œä¸å½±å“ç°æœ‰ç³»ç»Ÿ
- **ä¾¿äºæµ‹è¯•**ï¼šæ¯ä¸ªæ¨¡å—å¯ä»¥ç‹¬ç«‹æµ‹è¯•å’ŒéªŒè¯

### 1.2 æ ¸å¿ƒæ¨¡å—åˆ†ç±»

æ ¹æ®åŠŸèƒ½æ€§è´¨ï¼ŒRAGæ¡†æ¶çš„æ¨¡å—å¯ä»¥åˆ†ä¸ºä¸‰å¤§ç±»ï¼š

| æ¨¡å—ç±»åˆ« | åŒ…å«æ¨¡å— | ä¸»è¦èŒè´£ |
|---------|---------|----------|
| **ç´¢å¼•æ„å»ºæ¨¡å—** | æ–‡æ¡£åŠ è½½å™¨ã€æ–‡æœ¬åˆ†å‰²å™¨ã€åµŒå…¥æ¨¡å‹ã€å‘é‡å­˜å‚¨ | å°†åŸå§‹æ–‡æ¡£å¤„ç†å¹¶å­˜å‚¨ä¸ºå¯æ£€ç´¢çš„å‘é‡ç´¢å¼• |
| **æ£€ç´¢ç”Ÿæˆæ¨¡å—** | æ£€ç´¢å™¨ã€é“¾/ç®¡é“ã€ç”Ÿæˆå™¨ | æ ¹æ®ç”¨æˆ·æŸ¥è¯¢æ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶ç”Ÿæˆå›ç­” |
| **è¾…åŠ©æ”¯æŒæ¨¡å—** | è¯„ä¼°å™¨ã€æç¤ºè¯æ¨¡æ¿ã€ç¼“å­˜æœºåˆ¶ | è¯„ä¼°ç”Ÿæˆè´¨é‡ã€ä¼˜åŒ–æç¤ºè¯ã€æé«˜ç³»ç»Ÿæ€§èƒ½ |

### 1.3 fufanragæ¨¡å—æ¶æ„

```mermaid
flowchart TB
    subgraph "ç´¢å¼•æ„å»ºé˜¶æ®µ"
        A1["ğŸ“„ æ–‡æ¡£åŠ è½½å™¨<br/>Document Loaders"]:::loader
        A2["âœ‚ï¸ æ–‡æœ¬åˆ†å‰²å™¨<br/>Text Splitters"]:::splitter
        A3["ğŸ”¢ åµŒå…¥æ¨¡å‹<br/>Embeddings"]:::embeddings
        A4["ğŸ’¾ å‘é‡å­˜å‚¨<br/>Vector Stores"]:::vectorStore
    end

    subgraph "æ£€ç´¢ç”Ÿæˆé˜¶æ®µ"
        B1["ğŸ” æ£€ç´¢å™¨<br/>Retrievers"]:::retriever
        B2["ğŸ”— ç®¡é“<br/>Pipeline"]:::pipeline
        B3["ğŸ¤– ç”Ÿæˆå™¨<br/>LLMs"]:::generator
    end

    subgraph "è¾…åŠ©æ”¯æŒæ¨¡å—"
        C1["ğŸ“Š è¯„ä¼°å™¨<br/>Evaluator"]:::evaluator
        C2["ğŸ“ æç¤ºè¯æ¨¡æ¿<br/>Prompt Templates"]:::prompt
        C3["ğŸ’¨ ç¼“å­˜æœºåˆ¶<br/>Cache"]:::cache
    end

    A1 --> A2 --> A3 --> A4
    A4 -->|æŸ¥è¯¢| B1
    B1 --> B2 --> B3

    C1 -.->|è¯„ä¼°è´¨é‡| B2
    C2 -.->|æä¾›æ¨¡æ¿| B2
    C3 -.->|æ€§èƒ½ä¼˜åŒ–| A3

    classDef loader fill:#FF6B6B,stroke:#2D3436,stroke-width:3px,color:white,rx:8,ry:8;
    classDef splitter fill:#4ECDC4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef embeddings fill:#45B7D1,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef vectorStore fill:#96CEB4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef retriever fill:#FF9FF3,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef pipeline fill:#54A0FF,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef generator fill:#FECA57,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef evaluator fill:#E9ECEF,stroke:#2D3436,stroke-width:3px,color:#2D3436,rx:8,ry:8;
    classDef prompt fill:#FF6B6B,stroke:#2D3436,stroke-width:3px,color:white,rx:8,ry:8;
    classDef cache fill:#4ECDC4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
```

## 2. fufanragæ¨¡å—è¯¦ç»†åˆ†æ

### 2.1 fufanragç›®å½•ç»“æ„

```
fufanrag/
â”œâ”€â”€ config/              # é…ç½®ç®¡ç†æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py        # é…ç½®åŠ è½½å’Œåˆå§‹åŒ–
â”œâ”€â”€ data/                # æ•°æ®å­˜å‚¨ç›®å½•
â”‚   â”œâ”€â”€ indexes/         # ç´¢å¼•æ•°æ®
â”‚   â”œâ”€â”€ result/          # è¯„ä¼°ç»“æœ
â”‚   â””â”€â”€ test/            # æµ‹è¯•æ•°æ®
â”œâ”€â”€ dataset/             # æ•°æ®é›†ç®¡ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py       # æ•°æ®é›†å®¹å™¨ç±»
â”‚   â””â”€â”€ utils.py         # æ•°æ®é›†å·¥å…·å‡½æ•°
â”œâ”€â”€ evaluator/           # è¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluator.py     # è¯„ä¼°å™¨å®ç°
â”‚   â”œâ”€â”€ metrics.py       # è¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ utils.py         # è¯„ä¼°å·¥å…·
â”œâ”€â”€ generator/           # ç”Ÿæˆå™¨æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ generator.py     # LLMç”Ÿæˆå™¨
â”œâ”€â”€ pipeline/            # ç®¡é“æ¨¡å—ï¼ˆæ ¸å¿ƒåè°ƒå™¨ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ pipeline.py      # ç®¡é“å®ç°
â”œâ”€â”€ prompt/              # æç¤ºè¯æ¨¡æ¿
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ base_prompt.py   # æç¤ºè¯æ¨¡æ¿åŸºç±»
â”œâ”€â”€ retriever/           # æ£€ç´¢å™¨æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ encoder.py       # æ–‡æœ¬ç¼–ç å™¨
â”‚   â”œâ”€â”€ reranker.py      # é‡æ’åºæ¨¡å‹
â”‚   â”œâ”€â”€ retriever.py     # æ£€ç´¢å™¨å®ç°
â”‚   â””â”€â”€ utils.py         # æ£€ç´¢å·¥å…·å‡½æ•°
â””â”€â”€ utils/               # é€šç”¨å·¥å…·
    â”œâ”€â”€ __init__.py
    â””â”€â”€ utils.py         # å·¥å…·å‡½æ•°
```

### 2.2 æ•°æ®é›†æ¨¡å—ï¼ˆDatasetï¼‰

æ•°æ®é›†æ¨¡å—æ˜¯RAGç³»ç»Ÿçš„æ•°æ®è½½ä½“ï¼Œè´Ÿè´£ç®¡ç†è¯„ä¼°å’Œæµ‹è¯•ç”¨çš„é—®ç­”æ•°æ®ã€‚

#### æ ¸å¿ƒç±»è®¾è®¡

```python
# fufanrag/dataset/dataset.py

class Item:
    """
    å•ä¸ªæ•°æ®æ ·æœ¬å®¹å™¨ï¼Œå­˜å‚¨é—®ç­”å¯¹åŠç›¸å…³ä¿¡æ¯ã€‚
    """

    def __init__(self, item_dict):
        self.id = item_dict.get("id", None)
        self.question = item_dict.get("question", None)
        self.golden_answers = item_dict.get("golden_answers", [])
        self.metadata = item_dict.get("metadata", {})
        self.output = item_dict.get("output", {})


class Dataset:
    """
    æ•°æ®é›†å®¹å™¨ï¼Œç®¡ç†æ‰€æœ‰æ•°æ®æ ·æœ¬ã€‚
    """

    def __init__(self, config=None, dataset_path=None, data=None):
        self.config = config
        self.dataset_name = config['dataset_name']
        self.dataset_path = dataset_path
        self.data = self._load_data(self.dataset_name, self.dataset_path)

    def _load_data(self, dataset_name, dataset_path):
        """ä»JSONLæ–‡ä»¶åŠ è½½æ•°æ®"""
        data = []
        with open(dataset_path, "r", encoding="utf-8") as f:
            for line in f:
                item_dict = json.loads(line)
                item = Item(item_dict)
                data.append(item)
        return data
```

#### æ•°æ®æ ¼å¼ç¤ºä¾‹

```json
// fufanrag/data/test/test.jsonl
{"id": "1", "question": "ä»€ä¹ˆæ˜¯è·¯ç”±ä¿¡æ¯åè®®?", "golden_answers": ["è·¯ç”±ä¿¡æ¯åè®®ï¼ˆRouting Information Protocolï¼Œç¼©å†™ï¼šRIPï¼‰æ˜¯ä¸€ç§å†…éƒ¨ç½‘å…³åè®®ï¼ˆIGPï¼‰..."]}
{"id": "2", "question": "RIPåè®®å’ŒIGRPæœ‰ä»€ä¹ˆä¸åŒ?", "golden_answers": ["RIPåè®®å’ŒIGRPéƒ½æ˜¯è·¯ç”±ä¿¡æ¯åè®®ï¼Œä½†å®ƒä»¬ä¹‹é—´å­˜åœ¨ä¸€äº›ä¸åŒ..."]}
```

#### æ•°æ®é›†å±æ€§è®¿é—®

```mermaid
flowchart LR
    A["Datasetå®ä¾‹"] -->|question å±æ€§| B["[item.question for item in data]"]
    A -->|golden_answers å±æ€§| C["[item.golden_answers for item in data]"]
    A -->|id å±æ€§| D["[item.id for item in data]"]
    A -->|output å±æ€§| E["[item.output for item in data]"]

    classDef dataset fill:#54A0FF,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef attr fill:#96CEB4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef list fill:#FECA57,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;

    class A dataset
    class B,C,D,E attr
```

### 2.3 æ£€ç´¢å™¨æ¨¡å—ï¼ˆRetrieverï¼‰

æ£€ç´¢å™¨æ¨¡å—æ˜¯RAGç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£ã€‚

#### æ£€ç´¢å™¨æ¶æ„è®¾è®¡

```mermaid
flowchart TB
    subgraph "æ£€ç´¢å™¨ä½“ç³»"
        A["BaseRetriever<br/>æ£€ç´¢å™¨åŸºç±»"]:::base
        A --> B["BM25Retriever<br/>BM25å…³é”®è¯æ£€ç´¢"]:::bm25
        A --> C["DenseRetriever<br/>å¯†é›†å‘é‡æ£€ç´¢"]:::dense
    end

    subgraph "æ£€ç´¢è¾…åŠ©ç»„ä»¶"
        D["Encoder<br/>æ–‡æœ¬ç¼–ç å™¨"]:::encoder
        E["ReRanker<br/>é‡æ’åºæ¨¡å‹"]:::reranker
        F["Cache Manager<br/>ç¼“å­˜ç®¡ç†å™¨"]:::cache
    end

    subgraph "ç´¢å¼•å­˜å‚¨"
        G["Lucene Index<br/>BM25ç´¢å¼•"]:::lucene
        H["FAISS Index<br/>å‘é‡ç´¢å¼•"]:::faiss
        I["Corpus<br/>åŸå§‹è¯­æ–™åº“"]:::corpus
    end

    B --> G
    C --> H
    C --> D
    H --> I
    C -.->|é‡æ’åº| E
    B -.->|ç»“æœç¼“å­˜| F
    C -.->|ç»“æœç¼“å­˜| F

    classDef base fill:#FF6B6B,stroke:#2D3436,stroke-width:3px,color:white,rx:8,ry:8;
    classDef bm25 fill:#4ECDC4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef dense fill:#45B7D1,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef encoder fill:#96CEB4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef reranker fill:#FF9FF3,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef cache fill:#54A0FF,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef lucene fill:#FECA57,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef faiss fill:#E9ECEF,stroke:#2D3436,stroke-width:3px,color:#2D3436,rx:8,ry:8;
    classDef corpus fill:#FF6B6B,stroke:#2D3436,stroke-width:3px,color:white,rx:8,ry:8;
```

#### BM25æ£€ç´¢å™¨å®ç°

```python
# fufanrag/retriever/retriever.py

class BM25Retriever(BaseRetriever):
    """åŸºäºLuceneç´¢å¼•çš„BM25æ£€ç´¢å™¨"""

    def __init__(self, config):
        super().__init__(config)
        from pyserini.search.lucene import LuceneSearcher
        self.searcher = LuceneSearcher(self.index_path)
        self.contain_doc = self._check_contain_doc()
        if not self.contain_doc:
            self.corpus = load_corpus(self.corpus_path)

    def _search(self, query: str, num: int = None, return_score=False):
        if num is None:
            num = self.topk
        hits = self.searcher.search(query, num)
        scores = [hit.score for hit in hits]

        if self.contain_doc:
            all_contents = [json.loads(self.searcher.doc(hit.docid).raw())['contents']
                          for hit in hits]
            results = [{'title': content.split("\n")[0].strip("\""),
                       'text': "\n".join(content.split("\n")[1:]),
                       'contents': content} for content in all_contents]
        else:
            results = load_docs(self.corpus, [hit.docid for hit in hits])

        return (results, scores) if return_score else results
```

#### å¯†é›†å‘é‡æ£€ç´¢å™¨å®ç°

```python
# fufanrag/retriever/retriever.py

class DenseRetriever(BaseRetriever):
    """åŸºäºFAISSå‘é‡ç´¢å¼•çš„å¯†é›†æ£€ç´¢å™¨"""

    def __init__(self, config: dict):
        super().__init__(config)
        self.index = faiss.read_index(self.index_path)
        self.corpus = load_corpus(self.corpus_path)

        if config['use_sentence_transformer']:
            self.encoder = STEncoder(
                model_name=self.retrieval_method,
                model_path=config['retrieval_model_path'],
                max_length=config['retrieval_query_max_length'],
                use_fp16=config['retrieval_use_fp16']
            )
        else:
            self.encoder = Encoder(
                model_name=self.retrieval_method,
                model_path=config['retrieval_model_path'],
                pooling_method=config['retrieval_pooling_method'],
                max_length=config['retrieval_query_max_length'],
                use_fp16=config['retrieval_use_fp16']
            )

    def _search(self, query: str, num: int = None, return_score=False):
        if num is None:
            num = self.topk

        query_emb = self.encoder.encode(query)
        scores, idxs = self.index.search(query_emb, k=num)
        results = load_docs(self.corpus, idxs[0])

        return (results, scores[0]) if return_score else results
```

#### æ–‡æœ¬ç¼–ç å™¨å®ç°

```python
# fufanrag/retriever/encoder.py

class Encoder:
    """æ–‡æœ¬ç¼–ç å™¨ï¼Œå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡"""

    def __init__(self, model_name, model_path, pooling_method, max_length, use_fp16):
        self.model_name = model_name
        self.model_path = model_path
        self.pooling_method = pooling_method
        self.max_length = max_length
        self.use_fp16 = use_fp16

        self.model, self.tokenizer = load_model(
            model_path=model_path,
            use_fp16=use_fp16
        )

    @torch.no_grad()
    def encode(self, query_list: List[str], is_query=True) -> np.ndarray:
        query_list = parse_query(self.model_name, query_list, is_query)

        inputs = self.tokenizer(query_list,
                                max_length=self.max_length,
                                padding=True,
                                truncation=True,
                                return_tensors="pt")
        inputs = {k: v.cuda() for k, v in inputs.items()}

        output = self.model(**inputs, return_dict=True)
        query_emb = pooling(output.pooler_output,
                           output.last_hidden_state,
                           inputs['attention_mask'],
                           self.pooling_method)

        query_emb = query_emb.detach().cpu().numpy()
        return query_emb.astype(np.float32, order="C")
```

### 2.4 ç®¡é“æ¨¡å—ï¼ˆPipelineï¼‰

ç®¡é“æ¨¡å—æ˜¯RAGç³»ç»Ÿçš„æµç¨‹åè°ƒä¸­å¿ƒï¼Œè´Ÿè´£å°†å„ä¸ªç»„ä»¶ä¸²è”æˆå®Œæ•´çš„å·¥ä½œæµã€‚

#### ç®¡é“ä½“ç³»è®¾è®¡

```mermaid
flowchart TB
    subgraph "ç®¡é“ä½“ç³»"
        A["BasicPipeline<br/>åŸºç¡€ç®¡é“åŸºç±»"]:::base
        A --> B["SequentialPipeline<br/>é¡ºåºç®¡é“"]:::sequential
        A --> C["ConditionalPipeline<br/>æ¡ä»¶ç®¡é“"]:::conditional
    end

    subgraph "ç®¡é“æ ¸å¿ƒåŠŸèƒ½"
        D["æ£€ç´¢å™¨<br/>Retriever"]:::retriever
        E["ç”Ÿæˆå™¨<br/>Generator"]:::generator
        F["è¯„ä¼°å™¨<br/>Evaluator"]:::evaluator
        G["æç¤ºè¯æ¨¡æ¿<br/>Prompt Template"]:::prompt
    end

    subgraph "æ•°æ®æµè½¬"
        H["Dataset<br/>æ•°æ®é›†"]:::dataset
        I["Retrieval Results<br/>æ£€ç´¢ç»“æœ"]:::retrieval
        J["Generated Answers<br/>ç”Ÿæˆå›ç­”"]:::answers
    end

    B --> D --> E --> F
    C -->|æ™ºèƒ½åˆ¤æ–­| D
    C -->|ç›´æ¥ç”Ÿæˆ| E

    H --> B
    B --> I
    I --> E
    E --> J
    J --> F

    classDef base fill:#FF6B6B,stroke:#2D3436,stroke-width:3px,color:white,rx:8,ry:8;
    classDef sequential fill:#4ECDC4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef conditional fill:#45B7D1,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef retriever fill:#96CEB4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef generator fill:#FF9FF3,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef evaluator fill:#54A0FF,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef prompt fill:#FECA57,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef dataset fill:#E9ECEF,stroke:#2D3436,stroke-width:3px,color:#2D3436,rx:8,ry:8;
    classDef retrieval fill:#FF6B6B,stroke:#2D3436,stroke-width:3px,color:white,rx:8,ry:8;
    classDef answers fill:#4ECDC4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
```

#### åŸºç¡€ç®¡é“å®ç°

```python
# fufanrag/pipeline/pipeline.py

class BasicPipeline:
    """
    ç®¡é“åŸºç±»ï¼Œå®šä¹‰RAGæµç¨‹çš„åŸºæœ¬ç»“æ„å’Œæ¥å£ã€‚
    """

    def __init__(self, config, prompt_template=None):
        self.config = config
        self.device = config['device']
        self.retriever = None
        self.evaluator = Evaluator(config)
        self.save_retrieval_cache = config['save_retrieval_cache']

        if prompt_template is None:
            prompt_template = PromptTemplate(config)
        self.prompt_template = prompt_template

    def run(self, dataset):
        """æ‰§è¡ŒRAGæµç¨‹ï¼Œå­ç±»éœ€é‡å†™æ­¤æ–¹æ³•"""
        pass

    def evaluate(self, dataset, do_eval=True, pred_process_fun=None):
        """è¯„ä¼°ç”Ÿæˆç»“æœ"""
        if pred_process_fun is not None:
            raw_pred = dataset.pred
            processed_pred = [pred_process_fun(pred) for pred in raw_pred]
            dataset.update_output('raw_pred', raw_pred)
            dataset.update_output('pred', processed_pred)

        if do_eval:
            eval_result = self.evaluator.evaluate(dataset)
            print(eval_result)

        if self.save_retrieval_cache:
            self.retriever._save_cache()

        return dataset
```

#### é¡ºåºç®¡é“å®ç°

```python
# fufanrag/pipeline/pipeline.py

class SequentialPipeline(BasicPipeline):
    """
    é¡ºåºç®¡é“ï¼šæ ‡å‡†RAGæµç¨‹
    æµç¨‹ï¼šæŸ¥è¯¢ â†’ æ£€ç´¢ â†’ é‡æ’åº â†’ ç”Ÿæˆ â†’ è¯„ä¼°
    """

    def __init__(self, config, prompt_template=None):
        super().__init__(config, prompt_template)
        self.retriever = get_retriever(config)
        self.generator = get_generator(config)

    def run(self, dataset, do_eval=True, pred_process_fun=None):
        # 1. è·å–æŸ¥è¯¢
        input_query = dataset.question

        # 2. æ‰§è¡Œæ£€ç´¢
        retrieval_results = self.retriever.batch_search(input_query)
        dataset.update_output('retrieval_result', retrieval_results)

        # 3. æ„å»ºæç¤ºè¯
        input_prompts = [
            self.prompt_template.get_string(question=q, retrieval_result=r)
            for q, r in zip(dataset.question, dataset.retrieval_result)
        ]
        dataset.update_output('prompt', input_prompts)

        # 4. ç”Ÿæˆå›ç­”
        pred_answer_list = self.generator.generate(input_prompts)
        dataset.update_output("pred", pred_answer_list)

        # 5. è¯„ä¼°ç»“æœ
        dataset = self.evaluate(dataset, do_eval=do_eval, pred_process_fun=pred_process_fun)

        return dataset
```

### 2.5 æ£€ç´¢å™¨é€‰æ‹©æœºåˆ¶

```mermaid
flowchart LR
    A["é…ç½®å‚æ•°<br/>config"] --> B["get_retrieverå‡½æ•°<br/>å·¥å‚å‡½æ•°"]
    B -->|retrieval_method='bm25'| C["BM25Retriever<br/>BM25æ£€ç´¢å™¨"]
    B -->|retrieval_method='bge-*'| D["DenseRetriever<br/>å¯†é›†æ£€ç´¢å™¨"]

    subgraph "BM25æ£€ç´¢å™¨ç»„ä»¶"
        C --> C1["LuceneSearcher<br/>Luceneæœç´¢å™¨"]
        C1 --> C2["Lucene Index<br/>Luceneç´¢å¼•"]
    end

    subgraph "å¯†é›†æ£€ç´¢å™¨ç»„ä»¶"
        D --> D1["Encoder/STEncoder<br/>æ–‡æœ¬ç¼–ç å™¨"]
        D --> D2["FAISS Index<br/>FAISSç´¢å¼•"]
        D --> D3["Corpus<br/>åŸå§‹è¯­æ–™åº“"]
    end

    classDef config fill:#54A0FF,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef factory fill:#FF9FF3,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef bm25 fill:#4ECDC4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef dense fill:#45B7D1,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef component fill:#96CEB4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;

    class A config
    class B factory
    class C,C1,C2 bm25
    class D,D1,D2,D3 dense
```

```python
# fufanrag/utils/utils.py

def get_retriever(config):
    """æ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©æ£€ç´¢å™¨ç±»"""
    if config['retrieval_method'] == "bm25":
        return getattr(
            importlib.import_module("fufanrag.retriever"),
            "BM25Retriever"
        )(config)
    else:
        return getattr(
            importlib.import_module("fufanrag.retriever"),
            "DenseRetriever"
        )(config)
```

## 3. RAGå®Œæ•´å·¥ä½œæµç¨‹

### 3.1 æ•´ä½“æ•°æ®æµ

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant API as APIæ¥å£
    participant Pipeline as ç®¡é“æ¨¡å—
    participant Retriever as æ£€ç´¢å™¨
    participant Generator as ç”Ÿæˆå™¨
    participant Evaluator as è¯„ä¼°å™¨

    User->>API: å‘é€æŸ¥è¯¢é—®é¢˜
    API->>Pipeline: åŠ è½½æ•°æ®é›†
    Pipeline->>Retriever: æ‰¹é‡æ£€ç´¢ç›¸å…³æ–‡æ¡£
    Retriever-->>Pipeline: è¿”å›æ£€ç´¢ç»“æœ
    Pipeline->>Generator: æ„å»ºæç¤ºè¯å¹¶ç”Ÿæˆå›ç­”
    Generator-->>Pipeline: è¿”å›ç”Ÿæˆç»“æœ
    Pipeline->>Evaluator: è¯„ä¼°ç”Ÿæˆè´¨é‡
    Evaluator-->>Pipeline: è¿”å›è¯„ä¼°æŒ‡æ ‡
    Pipeline-->>API: è¿”å›å®Œæ•´ç»“æœ
    API-->>User: è¿”å›å›ç­”å’Œè¯„ä¼°ç»“æœ

    Note over User,Evaluator: æ•°æ®æµ: æŸ¥è¯¢é—®é¢˜ â†’ æ£€ç´¢ç›¸å…³æ–‡æ¡£ â†’ æ„å»ºæç¤ºè¯ â†’ ç”Ÿæˆå›ç­” â†’ è¯„ä¼°è´¨é‡ â†’ è¿”å›ç»“æœ
```

### 3.2 ç´¢å¼•æ„å»ºæµç¨‹

```mermaid
flowchart TB
    subgraph "ç´¢å¼•æ„å»ºé˜¶æ®µ"
        A["ğŸ“„ åŸå§‹æ–‡æ¡£<br/>Raw Documents"]:::doc
        A -->|æ–‡æ¡£åŠ è½½| B["ğŸ“– æ–‡æ¡£é¢„å¤„ç†<br/>Document Loader"]:::loader
        B -->|æ–‡æœ¬åˆ†å‰²| C["âœ‚ï¸ æ–‡æœ¬åˆ†å—<br/>Text Chunking"]:::chunk
        C -->|åµŒå…¥ç¼–ç | D["ğŸ”¢ åµŒå…¥æ¨¡å‹<br/>Embedding Model"]:::embed
        D -->|å‘é‡å­˜å‚¨| E["ğŸ’¾ å‘é‡ç´¢å¼•<br/>Vector Index"]:::index
        E -->|å…ƒæ•°æ®å­˜å‚¨| F["ğŸ“‹ è¯­æ–™åº“<br/>Corpus Metadata"]:::corpus
    end

    classDef doc fill:#FF6B6B,stroke:#2D3436,stroke-width:3px,color:white,rx:8,ry:8;
    classDef loader fill:#4ECDC4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef chunk fill:#45B7D1,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef embed fill:#96CEB4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef index fill:#FF9FF3,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef corpus fill:#54A0FF,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
```

### 3.3 æŸ¥è¯¢å¤„ç†æµç¨‹

```mermaid
flowchart TB
    subgraph "æŸ¥è¯¢å¤„ç†é˜¶æ®µ"
        A["â“ ç”¨æˆ·æŸ¥è¯¢<br/>User Query"]:::query
        A -->|æŸ¥è¯¢ç¼–ç | B["ğŸ”¢ æŸ¥è¯¢å‘é‡åŒ–<br/>Query Encoding"]:::encode
        B -->|ç›¸ä¼¼åº¦è®¡ç®—| C["ğŸ“Š å‘é‡æ£€ç´¢<br/>Vector Retrieval"]:::search
        C -->|ç»“æœé‡æ’åº| D["ğŸ¯ ç»“æœé‡æ’åº<br/>ReRanking"]:::rerank
        D -->|æ–‡æ¡£åŠ è½½| E["ğŸ“„ è·å–åŸå§‹æ–‡æ¡£<br/>Load Documents"]:::load
        E -->|æç¤ºè¯æ„å»º| F["ğŸ“ æç¤ºè¯æ¨¡æ¿<br/>Prompt Template"]:::prompt
        F -->|å›ç­”ç”Ÿæˆ| G["ğŸ¤– å¤§æ¨¡å‹ç”Ÿæˆ<br/>LLM Generation"]:::generate
        G -->|è´¨é‡è¯„ä¼°| H["ğŸ“ˆ ç»“æœè¯„ä¼°<br/>Evaluation"]:::eval
    end

    classDef query fill:#FF6B6B,stroke:#2D3436,stroke-width:3px,color:white,rx:8,ry:8;
    classDef encode fill:#4ECDC4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef search fill:#45B7D1,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef rerank fill:#96CEB4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef load fill:#FF9FF3,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef prompt fill:#54A0FF,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef generate fill:#FECA57,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef eval fill:#E9ECEF,stroke:#2D3436,stroke-width:3px,color:#2D3436,rx:8,ry:8;
```

### 3.4 ç®¡é“æ‰§è¡Œè¯¦ç»†æµç¨‹

```mermaid
sequenceDiagram
    participant Config as é…ç½®æ¨¡å—
    participant Dataset as æ•°æ®é›†
    participant Retriever as æ£€ç´¢å™¨
    participant Prompt as æç¤ºè¯æ¨¡æ¿
    participant Generator as ç”Ÿæˆå™¨
    participant Evaluator as è¯„ä¼°å™¨

    Config->>Dataset: åˆå§‹åŒ–æ•°æ®é›†
    Config->>Retriever: åˆå§‹åŒ–æ£€ç´¢å™¨
    Config->>Generator: åˆå§‹åŒ–ç”Ÿæˆå™¨
    Config->>Prompt: åˆå§‹åŒ–æç¤ºè¯æ¨¡æ¿
    Config->>Evaluator: åˆå§‹åŒ–è¯„ä¼°å™¨

    Dataset->>Retriever: batch_search(questions)
    Retriever-->>Dataset: retrieval_results

    loop æ¯ä¸ªé—®ç­”å¯¹
        Dataset->>Prompt: get_string(question, retrieval_result)
        Prompt-->>Dataset: prompt
        Dataset->>Generator: generate(prompts)
        Generator-->>Dataset: pred_answers
    end

    Dataset->>Evaluator: evaluate(dataset)
    Evaluator-->>Dataset: evaluation_scores

    Note over Config,Evaluator: å®Œæ•´RAGæµç¨‹: é…ç½®åˆå§‹åŒ– â†’ æ•°æ®åŠ è½½ â†’ æ‰¹é‡æ£€ç´¢ â†’ æç¤ºè¯æ„å»º â†’ ç”Ÿæˆå›ç­” â†’ è´¨é‡è¯„ä¼°
```

## 4. é…ç½®ç®¡ç†ä¸ä½¿ç”¨ç¤ºä¾‹

### 4.1 å®Œæ•´é…ç½®å‚æ•°

```python
# fufanrag/pipeline/pipeline.py (ç¤ºä¾‹é…ç½®)

config = {
    # çŸ¥è¯†åº“è·¯å¾„é…ç½®
    'dataset_path': '/path/to/test/data',
    "index_path": "/path/to/faiss/index.faiss",
    "corpus_path": "/path/to/corpus.jsonl",
    "retrieval_model_path": "/path/to/encoder/model",
    "retrieval_cache_path": "/path/to/cache",

    # ç”Ÿæˆæ¨¡å‹é…ç½®
    "generator_model": "chatglm3-6b",
    "generator_model_path": "/path/to/llm/model",

    # æ£€ç´¢é…ç½®
    'dataset_name': "test",
    'retrieval_method': 'bge-large-zh-v1',
    "retrieval_topk": 3,
    "use_reranker": False,
    "retrieval_pooling_method": "mean",
    "retrieval_batch_size": 12,

    # è¯„ä¼°é…ç½®
    "save_metric_score": True,
    "save_intermediate_data": True,
    "metrics": ['em', 'sub_em', 'f1', 'precision', 'recall'],

    # ç³»ç»Ÿé…ç½®
    "device": "cuda",
    "framework": "fschat"
}
```

### 4.2 ç®¡é“ä½¿ç”¨ç¤ºä¾‹

```python
# fufanrag/pipeline/pipeline.py (ä½¿ç”¨ç¤ºä¾‹)

from fufanrag.utils import get_dataset
from fufanrag.pipeline import SequentialPipeline
from fufanrag.prompt import PromptTemplate

# 1. é…ç½®å‚æ•°
config = {...}  # å¦‚ä¸Šæ‰€ç¤º

# 2. åŠ è½½æ•°æ®é›†
all_split = get_dataset(config)
test_data = all_split['test']

# 3. æ„å»ºæç¤ºæ¨¡æ¿
prompt_template = PromptTemplate(
    config,
    system_prompt="æ ¹æ®ç»™å®šæ–‡æ¡£å›ç­”é—®é¢˜ã€‚åªç»™å‡ºç­”æ¡ˆï¼Œä¸è¦è¾“å‡ºå…¶ä»–ä»»ä½•è¯è¯­ã€‚\nä¸‹é¢æ˜¯ç»™å®šçš„æ–‡æ¡£ã€‚\n\n{reference}",
    user_prompt="é—®é¢˜: {question}\nç­”æ¡ˆï¼š"
)

# 4. åˆå§‹åŒ–ç®¡é“
pipeline = SequentialPipeline(config, prompt_template=prompt_template)

# 5. æ‰§è¡ŒRAGæµç¨‹
output_dataset = pipeline.run(test_data, do_eval=True)

# 6. è·å–ç»“æœ
for response in output_dataset.pred:
    print(response)
```

## 5. ä¸å…¶ä»–RAGæ¡†æ¶çš„å¯¹æ¯”

### 5.1 æ¡†æ¶å¯¹æ¯”æ¦‚è§ˆ

| ç‰¹æ€§ | fufanrag | LangChain | LlamaIndex | Haystack |
|------|----------|-----------|------------|----------|
| **æ ¸å¿ƒæ¦‚å¿µ** | Pipeline | Chain | Query Engine | Pipeline |
| **æ¨¡å—åˆ’åˆ†** | ç»†ç²’åº¦ | ä¸­ç­‰ç²’åº¦ | ç²—ç²’åº¦ | ç»†ç²’åº¦ |
| **æ£€ç´¢æ–¹å¼** | BM25 + Dense | å¤šç§ | å¤šç§ | å¤šç§ |
| **è¯„ä¼°æ¨¡å—** | å†…ç½® | éœ€é›†æˆ | éœ€é›†æˆ | éœ€é›†æˆ |
| **é€‚ç”¨åœºæ™¯** | ç ”ç©¶è¯„ä¼° | é€šç”¨å¼€å‘ | ç´¢å¼•æ„å»º | ä¼ä¸šéƒ¨ç½² |
| **å­¦ä¹ æ›²çº¿** | ä¸­ç­‰ | è¾ƒä½ | ä½ | è¾ƒé«˜ |

### 5.2 ç®¡é“è®¾è®¡æ¨¡å¼å¯¹æ¯”

```mermaid
flowchart TB
    subgraph "fufanragç®¡é“è®¾è®¡"
        A1["SequentialPipeline"] --> A2["æ£€ç´¢å™¨"] --> A3["ç”Ÿæˆå™¨"] --> A4["è¯„ä¼°å™¨"]
    end

    subgraph "LangChainç®¡é“è®¾è®¡"
        B1["RetrievalQA Chain"] --> B2["Retriever"] --> B3["LLM"]
    end

    subgraph "LlamaIndexç®¡é“è®¾è®¡"
        C1["Query Engine"] --> C2["Retriever"] --> C3["Response Synthesizer"]
    end

    subgraph "Haystackç®¡é“è®¾è®¡"
        D1["Pipeline"] --> D2["Nodes"] --> D3["Generator"]
    end

    %% æ ·å¼ç±»å®šä¹‰ï¼ˆä¿®å¤è¯­æ³•é”™è¯¯ï¼‰
    classDef pipeline fill:#54A0FF,stroke:#2D3436,stroke-width:2px,color:white,rx:8,ry:8;
    classDef component fill:#4ECDC4,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;
    classDef llm fill:#FF6B6B,stroke:#2D3436,stroke-width:3px,color:white,rx:8,ry:8;
    classDef eval fill:#FECA57,stroke:#2D3436,stroke-width:2px,color:#2D3436,rx:8,ry:8;

    %% ä¸ºèŠ‚ç‚¹ç»‘å®šæ ·å¼ç±»
    class A1,B1,C1,D1 pipeline;       
    class A2,B2,C2,D2 component;      
    class A3,B3,C3,D3 llm;            
    class A4 eval;                    
```

## 6. æ€»ç»“ä¸æœ€ä½³å®è·µ

### 6.1 æ¨¡å—åŒ–è®¾è®¡çš„æ ¸å¿ƒä»·å€¼

fufanrag RAGæ¡†æ¶é€šè¿‡æ¨¡å—åŒ–è®¾è®¡å®ç°äº†ä»¥ä¸‹æ ¸å¿ƒä»·å€¼ï¼š

1. **æµç¨‹æ ‡å‡†åŒ–**ï¼šå®šä¹‰äº†æ¸…æ™°çš„RAGæµç¨‹æ¥å£ï¼Œä¾¿äºä¸åŒå®ç°çš„é›†æˆ
2. **ç»„ä»¶å¯æ›¿æ¢**ï¼šæ”¯æŒçµæ´»æ›¿æ¢æ£€ç´¢å™¨ã€ç”Ÿæˆå™¨ç­‰æ ¸å¿ƒç»„ä»¶
3. **è¯„ä¼°å†…ç½®åŒ–**ï¼šé›†æˆäº†å®Œæ•´çš„è¯„ä¼°æ¨¡å—ï¼Œä¾¿äºç³»ç»Ÿæ€§èƒ½è¯„ä¼°
4. **é…ç½®é©±åŠ¨**ï¼šé€šè¿‡é…ç½®æ–‡ä»¶ç®¡ç†æ‰€æœ‰å‚æ•°ï¼Œæé«˜ç³»ç»Ÿçš„çµæ´»æ€§

### 6.2 æœ€ä½³å®è·µå»ºè®®

| åœºæ™¯ | æ¨èé…ç½® | è¯´æ˜ |
|------|---------|------|
| **å…³é”®è¯æŸ¥è¯¢** | retrieval_method='bm25' | ä½¿ç”¨BM25æ£€ç´¢ï¼Œé€‚åˆç²¾ç¡®å…³é”®è¯åŒ¹é… |
| **è¯­ä¹‰æŸ¥è¯¢** | retrieval_method='bge-large-zh-v1' | ä½¿ç”¨å¯†é›†å‘é‡æ£€ç´¢ï¼Œé€‚åˆè¯­ä¹‰ç†è§£ |
| **é«˜è´¨é‡æ£€ç´¢** | use_reranker=True | å¯ç”¨é‡æ’åºï¼Œæé«˜æ£€ç´¢ç²¾åº¦ |
| **æ‰¹é‡å¤„ç†** | retrieval_batch_size=12 | è°ƒæ•´æ‰¹é‡å¤§å°ï¼Œä¼˜åŒ–å¤„ç†æ•ˆç‡ |

### 6.3 æ‰©å±•æ–¹å‘

fufanragæ¡†æ¶å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•ä»¥ä¸‹åŠŸèƒ½ï¼š

- **æ··åˆæ£€ç´¢**ï¼šåŒæ—¶ä½¿ç”¨BM25å’Œå¯†é›†æ£€ç´¢ï¼Œèåˆç»“æœ
- **å¤šçº§æ£€ç´¢**ï¼šå®ç°å¤šé˜¶æ®µæ£€ç´¢ï¼Œå¦‚ç²—æ’+ç²¾æ’
- **ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šæ”¯æŒå¯¹è¯å†å²çš„ä¸Šä¸‹æ–‡ç®¡ç†
- **æµå¼è¾“å‡º**ï¼šæ”¯æŒç”Ÿæˆç»“æœçš„æµå¼è¿”å›

é€šè¿‡æŒç»­çš„æ¨¡å—åŒ–è®¾è®¡å’Œä¼˜åŒ–ï¼Œfufanragå¯ä»¥æˆä¸ºä¸€ä¸ªåŠŸèƒ½å®Œå–„ã€æ€§èƒ½ä¼˜å¼‚çš„RAGæ¡†æ¶ã€‚
